{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "e89d322c-b879-4294-92c0-b8b8e9c4220b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOtoCOptna4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxnxLcUpCSKk",
        "colab_type": "text"
      },
      "source": [
        "# Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "colab": {}
      },
      "source": [
        "# Some functions we will use\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def colorplot(clf, ax, x, y, h=100):\n",
        "    '''\n",
        "    Overlay the decision areas as colors in an axes.\n",
        "    \n",
        "    Input:\n",
        "        clf: trained classifier\n",
        "        ax: axis to overlay color mesh on\n",
        "        x: feature on x-axis\n",
        "        y: feature on y-axis\n",
        "        h(optional): steps in the mesh\n",
        "    '''\n",
        "    # Create a meshgrid the size of the axis\n",
        "    xstep = (x.max() - x.min() ) / 20.0\n",
        "    ystep = (y.max() - y.min() ) / 20.0\n",
        "    x_min, x_max = x.min() - xstep, x.max() + xstep\n",
        "    y_min, y_max = y.min() - ystep, y.max() + ystep\n",
        "    h = max((x_max - x_min, y_max - y_min))/h\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    \n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    if hasattr(clf, \"decision_function\"):\n",
        "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "    else:\n",
        "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
        "    if len(Z.shape) > 1:\n",
        "        Z = Z[:, 1]\n",
        "    \n",
        "    # Put the result into a color plot\n",
        "    cm = plt.cm.RdBu_r\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
        "    del xx, yy, x_min, x_max, y_min, y_max, Z, cm\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQgfZ505VORH",
        "colab_type": "code",
        "outputId": "a27fa3e8-c99b-43bd-e083-ba5ad37b2dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Data loading functions. \n",
        "from adni.load_data import load_data \n",
        "\n",
        "data = load_data()\n",
        "print(data.head())\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "#data_missing = data.isnull()\n",
        "#print(data_missing.index[data_missing == True])\n",
        "\n",
        "# Creating vector of labels\n",
        "data_no_label = data.drop(columns='label')\n",
        "print(f'The number of features: {len(data_no_label.columns)}')\n",
        "x = data_no_label.values\n",
        "y = data['label'].values\n",
        "\n",
        "# Check if there is missing data in our dataset\n",
        "x_nan = np.isnan(x)\n",
        "print(f'The number of found NaN is: {np.sum(x_nan)}')\n",
        "x_zero = np.where(x == 0)[0]\n",
        "print(f'The number of found zeros is: {len(x_zero)}')\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.3)\n",
        "\n",
        "# Split data -> nog niet zeker welke te gebruiken\n",
        "'''\n",
        "# Of leave one out\n",
        "loo = LeaveOneOut()\n",
        "for train, test in loo.split(x):\n",
        "  pass\n",
        "'''\n",
        "\n",
        "\"\"\"\n",
        "Stukje van Eleen, doet bijna hetzelfde alleen heeft x nog kolomnamen\n",
        "# Creating vector of labels\n",
        "x = data.drop('label', axis=1)\n",
        "y = data['label'].values\n",
        "print(x)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "# Perform PCA -> Niet zeker of we dit nou moeten doen, n_features moet waarschijnlijk iets anders zijn\n",
        "n_features = len(data_no_label.columns) #ik denk dus dat dit alle features nu behoudt, maar snap nog niet helemaal hoe die PCA werkt\n",
        "p = PCA(n_components=n_features)\n",
        "p = p.fit(x)\n",
        "x = p.transform(x)\n",
        "\"\"\"\n",
        "\n",
        "# Build a forest and compute the feature importances. Bedenken of dit op training set of volledige set moet\n",
        "forest = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "forest.fit(X_train, y_train)\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X_train.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "\n",
        "# Plot the feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), indices)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 62\n",
            "                     hf_energy  ...  vf_Frangi_inner_std_SR(1.0, 10.0)_SS2.0\n",
            "ID                              ...                                         \n",
            "0_002_S_0413_bl_0  5403.229408  ...                             4.207831e-10\n",
            "0_002_S_0559_bl_0   922.459760  ...                             3.137258e-10\n",
            "0_002_S_0619_bl_0  1674.765276  ...                             4.219847e-10\n",
            "0_002_S_0685_bl_0  3443.797200  ...                             5.954654e-11\n",
            "0_002_S_0816_bl_0   914.469846  ...                             4.174750e-10\n",
            "\n",
            "[5 rows x 268 columns]\n",
            "The number of samples: 855\n",
            "The number of columns: 268\n",
            "The number of features: 267\n",
            "The number of found NaN is: 0\n",
            "The number of found zeros is: 6215\n",
            "Feature ranking:\n",
            "1. feature 224 (0.037733)\n",
            "2. feature 1 (0.035597)\n",
            "3. feature 2 (0.029471)\n",
            "4. feature 8 (0.027733)\n",
            "5. feature 11 (0.024245)\n",
            "6. feature 229 (0.023095)\n",
            "7. feature 106 (0.022433)\n",
            "8. feature 228 (0.020279)\n",
            "9. feature 76 (0.018158)\n",
            "10. feature 111 (0.016711)\n",
            "11. feature 105 (0.014928)\n",
            "12. feature 6 (0.013896)\n",
            "13. feature 140 (0.012633)\n",
            "14. feature 226 (0.011709)\n",
            "15. feature 160 (0.011343)\n",
            "16. feature 117 (0.011310)\n",
            "17. feature 119 (0.011166)\n",
            "18. feature 113 (0.011135)\n",
            "19. feature 230 (0.011084)\n",
            "20. feature 77 (0.010277)\n",
            "21. feature 143 (0.009066)\n",
            "22. feature 227 (0.007937)\n",
            "23. feature 168 (0.007671)\n",
            "24. feature 156 (0.007562)\n",
            "25. feature 137 (0.006865)\n",
            "26. feature 9 (0.006486)\n",
            "27. feature 221 (0.006458)\n",
            "28. feature 118 (0.006213)\n",
            "29. feature 161 (0.006127)\n",
            "30. feature 206 (0.005979)\n",
            "31. feature 114 (0.005885)\n",
            "32. feature 10 (0.005479)\n",
            "33. feature 180 (0.005307)\n",
            "34. feature 141 (0.005263)\n",
            "35. feature 7 (0.005242)\n",
            "36. feature 86 (0.005183)\n",
            "37. feature 209 (0.005138)\n",
            "38. feature 124 (0.005098)\n",
            "39. feature 150 (0.005072)\n",
            "40. feature 147 (0.004917)\n",
            "41. feature 154 (0.004748)\n",
            "42. feature 204 (0.004733)\n",
            "43. feature 148 (0.004692)\n",
            "44. feature 191 (0.004688)\n",
            "45. feature 136 (0.004671)\n",
            "46. feature 144 (0.004618)\n",
            "47. feature 55 (0.004489)\n",
            "48. feature 22 (0.004469)\n",
            "49. feature 125 (0.004466)\n",
            "50. feature 233 (0.004441)\n",
            "51. feature 171 (0.004404)\n",
            "52. feature 100 (0.004331)\n",
            "53. feature 145 (0.004294)\n",
            "54. feature 41 (0.004101)\n",
            "55. feature 85 (0.004051)\n",
            "56. feature 158 (0.004047)\n",
            "57. feature 61 (0.004000)\n",
            "58. feature 133 (0.003976)\n",
            "59. feature 18 (0.003970)\n",
            "60. feature 146 (0.003965)\n",
            "61. feature 109 (0.003924)\n",
            "62. feature 170 (0.003920)\n",
            "63. feature 108 (0.003809)\n",
            "64. feature 149 (0.003808)\n",
            "65. feature 153 (0.003780)\n",
            "66. feature 202 (0.003753)\n",
            "67. feature 232 (0.003753)\n",
            "68. feature 212 (0.003730)\n",
            "69. feature 82 (0.003728)\n",
            "70. feature 173 (0.003700)\n",
            "71. feature 188 (0.003633)\n",
            "72. feature 165 (0.003624)\n",
            "73. feature 4 (0.003623)\n",
            "74. feature 5 (0.003552)\n",
            "75. feature 134 (0.003496)\n",
            "76. feature 162 (0.003483)\n",
            "77. feature 97 (0.003465)\n",
            "78. feature 199 (0.003420)\n",
            "79. feature 245 (0.003400)\n",
            "80. feature 211 (0.003350)\n",
            "81. feature 98 (0.003303)\n",
            "82. feature 169 (0.003278)\n",
            "83. feature 157 (0.003260)\n",
            "84. feature 17 (0.003248)\n",
            "85. feature 107 (0.003208)\n",
            "86. feature 208 (0.003204)\n",
            "87. feature 181 (0.003176)\n",
            "88. feature 159 (0.003174)\n",
            "89. feature 84 (0.003174)\n",
            "90. feature 126 (0.003157)\n",
            "91. feature 195 (0.003120)\n",
            "92. feature 177 (0.003104)\n",
            "93. feature 129 (0.003096)\n",
            "94. feature 70 (0.003092)\n",
            "95. feature 182 (0.003084)\n",
            "96. feature 198 (0.003062)\n",
            "97. feature 102 (0.003059)\n",
            "98. feature 185 (0.003051)\n",
            "99. feature 207 (0.003051)\n",
            "100. feature 223 (0.003019)\n",
            "101. feature 196 (0.002997)\n",
            "102. feature 135 (0.002988)\n",
            "103. feature 40 (0.002957)\n",
            "104. feature 193 (0.002906)\n",
            "105. feature 91 (0.002899)\n",
            "106. feature 21 (0.002899)\n",
            "107. feature 256 (0.002899)\n",
            "108. feature 166 (0.002895)\n",
            "109. feature 15 (0.002884)\n",
            "110. feature 26 (0.002883)\n",
            "111. feature 244 (0.002875)\n",
            "112. feature 58 (0.002868)\n",
            "113. feature 179 (0.002864)\n",
            "114. feature 265 (0.002852)\n",
            "115. feature 16 (0.002804)\n",
            "116. feature 190 (0.002788)\n",
            "117. feature 139 (0.002780)\n",
            "118. feature 46 (0.002770)\n",
            "119. feature 178 (0.002770)\n",
            "120. feature 130 (0.002768)\n",
            "121. feature 187 (0.002767)\n",
            "122. feature 93 (0.002728)\n",
            "123. feature 45 (0.002728)\n",
            "124. feature 35 (0.002714)\n",
            "125. feature 73 (0.002705)\n",
            "126. feature 152 (0.002694)\n",
            "127. feature 121 (0.002653)\n",
            "128. feature 14 (0.002647)\n",
            "129. feature 192 (0.002631)\n",
            "130. feature 51 (0.002629)\n",
            "131. feature 112 (0.002624)\n",
            "132. feature 201 (0.002615)\n",
            "133. feature 238 (0.002605)\n",
            "134. feature 52 (0.002546)\n",
            "135. feature 222 (0.002531)\n",
            "136. feature 28 (0.002506)\n",
            "137. feature 67 (0.002460)\n",
            "138. feature 110 (0.002456)\n",
            "139. feature 220 (0.002423)\n",
            "140. feature 101 (0.002419)\n",
            "141. feature 65 (0.002409)\n",
            "142. feature 79 (0.002406)\n",
            "143. feature 167 (0.002402)\n",
            "144. feature 116 (0.002397)\n",
            "145. feature 64 (0.002382)\n",
            "146. feature 49 (0.002361)\n",
            "147. feature 39 (0.002351)\n",
            "148. feature 103 (0.002347)\n",
            "149. feature 250 (0.002347)\n",
            "150. feature 75 (0.002322)\n",
            "151. feature 90 (0.002320)\n",
            "152. feature 241 (0.002318)\n",
            "153. feature 62 (0.002301)\n",
            "154. feature 184 (0.002288)\n",
            "155. feature 257 (0.002261)\n",
            "156. feature 96 (0.002247)\n",
            "157. feature 59 (0.002222)\n",
            "158. feature 99 (0.002213)\n",
            "159. feature 66 (0.002203)\n",
            "160. feature 88 (0.002199)\n",
            "161. feature 29 (0.002190)\n",
            "162. feature 210 (0.002190)\n",
            "163. feature 163 (0.002186)\n",
            "164. feature 57 (0.002186)\n",
            "165. feature 262 (0.002176)\n",
            "166. feature 3 (0.002160)\n",
            "167. feature 205 (0.002154)\n",
            "168. feature 42 (0.002154)\n",
            "169. feature 74 (0.002127)\n",
            "170. feature 197 (0.002123)\n",
            "171. feature 13 (0.002118)\n",
            "172. feature 20 (0.002091)\n",
            "173. feature 253 (0.002084)\n",
            "174. feature 215 (0.002083)\n",
            "175. feature 174 (0.002070)\n",
            "176. feature 56 (0.002065)\n",
            "177. feature 34 (0.002049)\n",
            "178. feature 63 (0.002040)\n",
            "179. feature 213 (0.002039)\n",
            "180. feature 36 (0.002035)\n",
            "181. feature 183 (0.002003)\n",
            "182. feature 164 (0.001985)\n",
            "183. feature 104 (0.001984)\n",
            "184. feature 19 (0.001981)\n",
            "185. feature 53 (0.001921)\n",
            "186. feature 48 (0.001913)\n",
            "187. feature 155 (0.001913)\n",
            "188. feature 89 (0.001907)\n",
            "189. feature 225 (0.001903)\n",
            "190. feature 194 (0.001871)\n",
            "191. feature 203 (0.001869)\n",
            "192. feature 95 (0.001848)\n",
            "193. feature 50 (0.001846)\n",
            "194. feature 27 (0.001822)\n",
            "195. feature 60 (0.001777)\n",
            "196. feature 72 (0.001762)\n",
            "197. feature 78 (0.001760)\n",
            "198. feature 43 (0.001759)\n",
            "199. feature 25 (0.001750)\n",
            "200. feature 138 (0.001746)\n",
            "201. feature 151 (0.001743)\n",
            "202. feature 12 (0.001742)\n",
            "203. feature 189 (0.001717)\n",
            "204. feature 92 (0.001650)\n",
            "205. feature 31 (0.001632)\n",
            "206. feature 115 (0.001621)\n",
            "207. feature 172 (0.001586)\n",
            "208. feature 44 (0.001543)\n",
            "209. feature 94 (0.001537)\n",
            "210. feature 142 (0.001524)\n",
            "211. feature 200 (0.001522)\n",
            "212. feature 32 (0.001485)\n",
            "213. feature 38 (0.001437)\n",
            "214. feature 120 (0.001398)\n",
            "215. feature 37 (0.001380)\n",
            "216. feature 128 (0.001372)\n",
            "217. feature 176 (0.001357)\n",
            "218. feature 33 (0.001350)\n",
            "219. feature 0 (0.001337)\n",
            "220. feature 47 (0.001301)\n",
            "221. feature 87 (0.001299)\n",
            "222. feature 186 (0.001271)\n",
            "223. feature 127 (0.001268)\n",
            "224. feature 123 (0.001214)\n",
            "225. feature 54 (0.001212)\n",
            "226. feature 122 (0.001126)\n",
            "227. feature 131 (0.001119)\n",
            "228. feature 30 (0.001102)\n",
            "229. feature 132 (0.001056)\n",
            "230. feature 24 (0.000991)\n",
            "231. feature 175 (0.000917)\n",
            "232. feature 23 (0.000795)\n",
            "233. feature 218 (0.000122)\n",
            "234. feature 83 (0.000000)\n",
            "235. feature 254 (0.000000)\n",
            "236. feature 246 (0.000000)\n",
            "237. feature 247 (0.000000)\n",
            "238. feature 248 (0.000000)\n",
            "239. feature 249 (0.000000)\n",
            "240. feature 251 (0.000000)\n",
            "241. feature 252 (0.000000)\n",
            "242. feature 255 (0.000000)\n",
            "243. feature 242 (0.000000)\n",
            "244. feature 258 (0.000000)\n",
            "245. feature 259 (0.000000)\n",
            "246. feature 260 (0.000000)\n",
            "247. feature 261 (0.000000)\n",
            "248. feature 263 (0.000000)\n",
            "249. feature 264 (0.000000)\n",
            "250. feature 243 (0.000000)\n",
            "251. feature 240 (0.000000)\n",
            "252. feature 81 (0.000000)\n",
            "253. feature 239 (0.000000)\n",
            "254. feature 237 (0.000000)\n",
            "255. feature 236 (0.000000)\n",
            "256. feature 235 (0.000000)\n",
            "257. feature 234 (0.000000)\n",
            "258. feature 68 (0.000000)\n",
            "259. feature 69 (0.000000)\n",
            "260. feature 231 (0.000000)\n",
            "261. feature 219 (0.000000)\n",
            "262. feature 217 (0.000000)\n",
            "263. feature 216 (0.000000)\n",
            "264. feature 71 (0.000000)\n",
            "265. feature 214 (0.000000)\n",
            "266. feature 80 (0.000000)\n",
            "267. feature 266 (0.000000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEICAYAAACeSMncAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGnMQMTOzxhxEzMysMQcRMzNr7P8DuqxeTosQvhgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}