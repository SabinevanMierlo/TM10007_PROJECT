{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "418639f3-4947-4dbc-ef6a-e6fe907ce765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOtoCOptna4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "from sklearn.linear_model import Lasso, RidgeClassifier\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxnxLcUpCSKk",
        "colab_type": "text"
      },
      "source": [
        "# Data loading and cleaning\n",
        "\n",
        "Some functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "colab": {}
      },
      "source": [
        "# Some functions we will use\n",
        "\n",
        "\n",
        "def colorplot(clf, ax, x, y, h=100):\n",
        "    '''\n",
        "    Overlay the decision areas as colors in an axes.\n",
        "    \n",
        "    Input:\n",
        "        clf: trained classifier\n",
        "        ax: axis to overlay color mesh on\n",
        "        x: feature on x-axis\n",
        "        y: feature on y-axis\n",
        "        h(optional): steps in the mesh\n",
        "    '''\n",
        "    # Create a meshgrid the size of the axis\n",
        "    xstep = (x.max() - x.min() ) / 20.0\n",
        "    ystep = (y.max() - y.min() ) / 20.0\n",
        "    x_min, x_max = x.min() - xstep, x.max() + xstep\n",
        "    y_min, y_max = y.min() - ystep, y.max() + ystep\n",
        "    h = max((x_max - x_min, y_max - y_min))/h\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    \n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    if hasattr(clf, \"decision_function\"):\n",
        "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "    else:\n",
        "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
        "    if len(Z.shape) > 1:\n",
        "        Z = Z[:, 1]\n",
        "    \n",
        "    # Put the result into a color plot\n",
        "    cm = plt.cm.RdBu_r\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
        "    del xx, yy, x_min, x_max, y_min, y_max, Z, cm\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate 3 plots: the test and training learning curve, the training\n",
        "    samples vs fit times curve, the fit times vs score curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    axes : array of 3 axes, optional (default=None)\n",
        "        Axes to use for plotting the curves.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 5-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "        Note that for classification the number of samples usually have to\n",
        "        be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "\n",
        "    axes.set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes.set_ylim(*ylim)\n",
        "    axes.set_xlabel(\"Training examples\")\n",
        "    axes.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores  = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes.grid()\n",
        "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    return plt\n",
        "\n",
        "def plot_roc_curve(y_score, y_truth):\n",
        "    '''\n",
        "    Plot an ROC curve.\n",
        "    '''\n",
        "    # Only take scores for class = 1\n",
        "    y_score = y_score[:, 1]\n",
        "    \n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr, tpr, _ = roc_curve(y_truth, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    \n",
        "    # Plot the ROC curve\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange',\n",
        "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k6pUnYWV4GG",
        "colab_type": "text"
      },
      "source": [
        "Data loading and handling missing data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQgfZ505VORH",
        "colab_type": "code",
        "outputId": "d228ac31-f96e-404c-eb23-1c756bc5ab4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Data loading functions. \n",
        "from adni.load_data import load_data \n",
        "\n",
        "data = load_data()\n",
        "print(data.head())\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "#data_missing = data.isnull()\n",
        "#print(data_missing.index[data_missing == True])\n",
        "\n",
        "# Creating vector of labels\n",
        "data_no_label = data.drop(columns='label')\n",
        "print(f'The number of features: {len(data_no_label.columns)}')\n",
        "x = data_no_label\n",
        "y = data['label']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "def removezeros(X):\n",
        "   X_nozeros = X.loc[:, (X != 0).any(axis=0)]\n",
        "   return X_nozeros\n",
        "\n",
        "X_train_df = removezeros(X_train)\n",
        "X_test_df = removezeros(X_test)\n",
        "print(f'The number of samples: {len(X_train_df.index)}')\n",
        "print(f'The number of columns: {len(X_train_df.columns)}')\n",
        "X_train = X_train_df.values\n",
        "X_test = X_test_df.values\n",
        "\n",
        "x_nan = np.isnan(X_train)\n",
        "print(f'The number of found NaN is: {np.sum(x_nan)}')\n",
        "#x_zero = np.where(X_train == 0)[0]\n",
        "#print(f'The number of found zeros is: {len(x_zero)}')\n",
        "\n",
        "y_train_bin = preprocessing.label_binarize(y_train,['AD','CN'])\n",
        "y_train_bin = [i[0] for i in y_train_bin]\n",
        "y_test_bin = preprocessing.label_binarize(y_test,['AD','CN'])\n",
        "y_test_bin = [i[0] for i in y_test_bin]\n",
        "#print(y_train_bin)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     hf_energy  ...  vf_Frangi_inner_std_SR(1.0, 10.0)_SS2.0\n",
            "ID                              ...                                         \n",
            "0_002_S_0413_bl_0  5403.229408  ...                             4.207831e-10\n",
            "0_002_S_0559_bl_0   922.459760  ...                             3.137258e-10\n",
            "0_002_S_0619_bl_0  1674.765276  ...                             4.219847e-10\n",
            "0_002_S_0685_bl_0  3443.797200  ...                             5.954654e-11\n",
            "0_002_S_0816_bl_0   914.469846  ...                             4.174750e-10\n",
            "\n",
            "[5 rows x 268 columns]\n",
            "The number of samples: 855\n",
            "The number of columns: 268\n",
            "The number of features: 267\n",
            "The number of samples: 684\n",
            "The number of columns: 263\n",
            "The number of found NaN is: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwTNunQvVPEp",
        "colab_type": "text"
      },
      "source": [
        "# Feature scaling and selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUayp0qrWIuY",
        "colab_type": "code",
        "outputId": "b7504718-e3d2-4161-fd00-66cc8cf13141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "# Scaling of features\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature selection - L1 method\n",
        "selector = SelectFromModel(estimator=Lasso(alpha=10**(-10), random_state=42), threshold='median')\n",
        "selector.fit(X_train_scaled, y_train_bin)\n",
        "n_original = X_train_scaled.shape[1]\n",
        "X_train_test = selector.transform(X_train_scaled)\n",
        "n_selected = X_train_test.shape[1]\n",
        "print(f\"Selected {n_selected} from {n_original} features.\")\n",
        "\n",
        "# PCA\n",
        "pca = PCA().fit(X_train_scaled)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');\n",
        "\n",
        "pca = PCA(n_components=132)\n",
        "pca = pca.fit(X_train_scaled)\n",
        "X_train = pca.transform(X_train_scaled)\n",
        "X_test = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Create the RFE object and compute a cross-validated score.\n",
        "svc = SVC(kernel=\"linear\")\n",
        "# The \"accuracy\" scoring is proportional to the number of correct\n",
        "# classifications\n",
        "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
        "              scoring='roc_auc')\n",
        "select = rfecv.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()\n",
        "\n",
        "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
        "\"\"\""
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-971e2094bb36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Feature selection - L1 method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (171,262) (263,) (171,262) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9EzZYBrqjX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNz47vkCHQGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# Get new X_train with only important features \n",
        "features = X_train_df * select.support_\n",
        "x_train_df = removezeros(features)\n",
        "x_train = x_train_df.values\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwqLx_t_R-d0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# Train Classifier  \n",
        "# defining parameter range \n",
        "param_grid = {'C': loguniform(1e0, 1e3), \n",
        "              'gamma': loguniform(1e-4, 1e0), \n",
        "              'kernel': ['rbf','poly', 'linear']}  \n",
        "  \n",
        "grid = RandomizedSearchCV(SVC(probability=True), param_grid, n_iter=10, refit = True, verbose = 3, random_state=42) \n",
        "  \n",
        "# fitting the model for grid search \n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"The best classifier is: \", grid.best_estimator_)\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ghflhYlTBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "score_train = grid.best_estimator_.predict_proba(X_train)\n",
        "score_test = grid.best_estimator_.predict_proba(X_test)\n",
        "plot_roc_curve(score_train, y_train_bin)\n",
        "plot_roc_curve(score_test, y_test_bin)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq87at2Nqlsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kNN\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "kNN_parameters = {'n_neighbors': list(range(1,101)), \n",
        "                   'weights':  ['uniform', 'distance'],\n",
        "                   'metric': ['euclidean', 'manhattan']}\n",
        "\n",
        "grid = RandomizedSearchCV(KNeighborsClassifier(), kNN_parameters, refit = True, n_iter=10, random_state=42, verbose = 3)  \n",
        "# fitting the model for grid search \n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"The best classifier is: \", grid.best_estimator_)\n",
        "\n",
        "score_train = grid.best_estimator_.predict_proba(X_train)\n",
        "score_test = grid.best_estimator_.predict_proba(X_test)\n",
        "plot_roc_curve(score_train, y_train_bin)\n",
        "plot_roc_curve(score_test, y_test_bin)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}