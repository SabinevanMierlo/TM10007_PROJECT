{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment: ADNI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "09d2e388-61bc-46f1-c431-37daefb4a0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntIj3qfhreFu",
        "colab_type": "text"
      },
      "source": [
        "# Import necessary functions/packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOtoCOptna4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "from scipy import interp\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import Lasso, RidgeClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import LeaveOneOut, KFold, StratifiedKFold, RandomizedSearchCV, cross_validate\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "# Statistics\n",
        "from statistics import mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxnxLcUpCSKk",
        "colab_type": "text"
      },
      "source": [
        "# Some functions we will use "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "colab": {}
      },
      "source": [
        "def removezeros(X):\n",
        "  '''\n",
        "  Remove features with only zero's as values\n",
        "  '''\n",
        "  X_nozeros = X.loc[:, (X != 0).any(axis=0)]\n",
        "  return X_nozeros\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate 3 plots: the test and training learning curve, the training\n",
        "    samples vs fit times curve, the fit times vs score curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    axes : array of 3 axes, optional (default=None)\n",
        "        Axes to use for plotting the curves.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 5-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "        Note that for classification the number of samples usually have to\n",
        "        be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "\n",
        "    axes.set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes.set_ylim(*ylim)\n",
        "    axes.set_xlabel(\"Training examples\")\n",
        "    axes.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores  = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes.grid()\n",
        "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    return plt\n",
        "\n",
        "def plot_roc_curve(y_score, y_truth):\n",
        "    '''\n",
        "    Plot an ROC curve.\n",
        "    '''\n",
        "    # Only take scores for class = 1\n",
        "    y_score = y_score[:, 1]\n",
        "    \n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr, tpr, _ = roc_curve(y_truth, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    \n",
        "    # Plot the ROC curve\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange',\n",
        "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k6pUnYWV4GG",
        "colab_type": "text"
      },
      "source": [
        "# Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQgfZ505VORH",
        "colab_type": "code",
        "outputId": "278a8326-6520-4c29-8a79-2a3226f34384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "# Data loading functions\n",
        "from adni.load_data import load_data \n",
        "data = load_data()\n",
        "print(data.head())\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "\"\"\" \n",
        "kan dit weg?\n",
        "#data_missing = data.isnull()\n",
        "#print(data_missing.index[data_missing == True])\n",
        "\"\"\"\n",
        "\n",
        "# Creating vector of labels\n",
        "data_no_label = data.drop(columns='label')\n",
        "print(f'The number of features: {len(data_no_label.columns)}')\n",
        "x = data_no_label\n",
        "y = data['label']\n",
        "\n",
        "# Split data in train and test set\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "# Remove features with only zero's as values\n",
        "X_train_df = removezeros(X_train)\n",
        "X_test_df = removezeros(X_test)\n",
        "print(f'The number of samples: {len(X_train_df.index)}') # kan dit weg?\n",
        "print(f'The number of features after removing zero-features: {len(X_train_df.columns)}')\n",
        "\n",
        "# Get values of of the features\n",
        "X_train = X_train_df.values\n",
        "X_test = X_test_df.values\n",
        "\n",
        "# Check if there are NaN's\n",
        "x_nan = np.isnan(X_train)\n",
        "print(f'The number of found NaN is: {np.sum(x_nan)}')\n",
        "\"\"\" moeten we dit eigenlijk ook niet doen voor de test?\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "kan dit weg?\n",
        "#x_zero = np.where(X_train == 0)[0]\n",
        "#print(f'The number of found zeros is: {len(x_zero)}')\n",
        "\"\"\"\n",
        "\n",
        "# Binarize the labels\n",
        "y_train_bin = preprocessing.label_binarize(y_train,['AD','CN'])\n",
        "y_train_bin = [i[0] for i in y_train_bin]\n",
        "y_test_bin = preprocessing.label_binarize(y_test,['AD','CN'])\n",
        "y_test_bin = [i[0] for i in y_test_bin]\n",
        "y_bin = preprocessing.label_binarize(y,['AD','CN'])\n",
        "y_bin = [i[0] for i in y_bin]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     hf_energy  ...  vf_Frangi_inner_std_SR(1.0, 10.0)_SS2.0\n",
            "ID                              ...                                         \n",
            "0_002_S_0413_bl_0  5403.229408  ...                             4.207831e-10\n",
            "0_002_S_0559_bl_0   922.459760  ...                             3.137258e-10\n",
            "0_002_S_0619_bl_0  1674.765276  ...                             4.219847e-10\n",
            "0_002_S_0685_bl_0  3443.797200  ...                             5.954654e-11\n",
            "0_002_S_0816_bl_0   914.469846  ...                             4.174750e-10\n",
            "\n",
            "[5 rows x 268 columns]\n",
            "The number of samples: 855\n",
            "The number of columns: 268\n",
            "The number of features: 267\n",
            "The number of samples: 684\n",
            "The number of features after removing zero-features: 263\n",
            "The number of found NaN is: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwTNunQvVPEp",
        "colab_type": "text"
      },
      "source": [
        "# Feature scaling and selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUayp0qrWIuY",
        "colab_type": "code",
        "outputId": "77c4e821-b963-47ca-d760-f19e59b9dab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Scaling of features\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature selection - L1 method\n",
        "selector = SelectFromModel(estimator=Lasso(alpha=10**(-10), random_state=42), threshold='median')\n",
        "selector.fit(X_train_scaled, y_train_bin)\n",
        "n_original = X_train_scaled.shape[1]\n",
        "X_train_test = selector.transform(X_train_scaled)\n",
        "n_selected = X_train_test.shape[1]\n",
        "print(f\"Selected {n_selected} from {n_original} features with L1 method.\")\n",
        "\n",
        "# PCA\n",
        "pca = PCA().fit(X_train_scaled)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');\n",
        "\n",
        "# Feature selection - PCA\n",
        "pca = PCA(n_components=132)\n",
        "pca = pca.fit(X_train_scaled)\n",
        "X_train = pca.transform(X_train_scaled)\n",
        "X_test = pca.transform(X_test_scaled)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-62687e1714e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Feature selection - L1 method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (171,262) (263,) (171,262) "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jj80MsZsOHO",
        "colab_type": "text"
      },
      "source": [
        "# SVM classifier\n",
        "Hyperparameter optimization of SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwqLx_t_R-d0",
        "colab_type": "code",
        "outputId": "26f2a71b-1457-4b0c-b3ce-692df01f922d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        " # Define hyperparameters for SVM \n",
        "SVM_param = {'C': loguniform(1e0, 1e3), \n",
        "              'gamma': loguniform(1e-4, 1e0), \n",
        "              'kernel': ['rbf','poly', 'linear']}  \n",
        "\n",
        "# Perform randomized search with cross-validation for hyperparameter optimization\n",
        "grid = RandomizedSearchCV(SVC(probability=True), SVM_param, n_iter=10, refit = True, verbose = 3, random_state=42) \n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"The best classifier is: \", grid.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] C=13.292918943162162, gamma=0.6351221010640693, kernel=linear ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV2ZyzChvvc3",
        "colab_type": "text"
      },
      "source": [
        "ROC of SVM for train- and test-set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ghflhYlTBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determine scores for train and test set\n",
        "score_train = grid.best_estimator_.predict_proba(X_train)\n",
        "score_test = grid.best_estimator_.predict_proba(X_test)\n",
        "\n",
        "# Plot ROC curve for train and test set\n",
        "plot_roc_curve(score_train, y_train_bin)\n",
        "plot_roc_curve(score_test, y_test_bin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN_I8VNJv8jE",
        "colab_type": "text"
      },
      "source": [
        "Calculate metrics of SVM with cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCJeXnxBwFXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the scoring metrics\n",
        "scoring = ['precision', 'recall', 'f1', 'accuracy','roc_auc']\n",
        "\n",
        "# Calculate the scores with cross-validation\n",
        "scores = cross_validate(grid.best_estimator_, x.values, y_bin, scoring=scoring, cv=20)\n",
        "\n",
        "# Calculate the means of the score\n",
        "mean_accuracy = mean(scores['test_accuracy'])\n",
        "mean_precision = mean(scores['test_precision'])\n",
        "mean_f1 = mean(scores['test_f1'])\n",
        "mean_roc_auc = mean(scores['test_roc_auc'])\n",
        "mean_recall = mean(scores['test_recall'])\n",
        "print(f'mean accuracy is {mean_accuracy}')\n",
        "print(f'mean precision is {mean_precision}')\n",
        "print(f'mean f1 is {mean_f1}')\n",
        "print(f'mean roc_auc is {mean_roc_auc}')\n",
        "print(f'mean recall is {mean_recall}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yy6mdV2tSFU",
        "colab_type": "text"
      },
      "source": [
        "# kNN classifier\n",
        "Hyperparameter optimization of kNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq87at2Nqlsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hyperparameters for kNN\n",
        "kNN_parameters = {'n_neighbors': list(range(1,101)), \n",
        "                   'weights':  ['uniform', 'distance'],\n",
        "                   'metric': ['euclidean', 'manhattan']}\n",
        "\n",
        "# Perform randomized search with cross-validation for hyperparameter optimization\n",
        "grid = RandomizedSearchCV(KNeighborsClassifier(), kNN_parameters, refit = True, n_iter=10, random_state=42, verbose = 3)  \n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"The best classifier is: \", grid.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T8QAGgVwfyy",
        "colab_type": "text"
      },
      "source": [
        "ROC of kNN for train- and test-set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG5RbngOvNUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determine scores for train and test set\n",
        "score_train = grid.best_estimator_.predict_proba(X_train)\n",
        "score_test = grid.best_estimator_.predict_proba(X_test)\n",
        "\n",
        "# Plot ROC curve for train and test set\n",
        "plot_roc_curve(score_train, y_train_bin)\n",
        "plot_roc_curve(score_test, y_test_bin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc_QuJn8xImO",
        "colab_type": "text"
      },
      "source": [
        "Calculate metrics of kNN with cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E7NVCR1xI5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the scoring metrics\n",
        "scoring = ['precision', 'recall', 'f1', 'accuracy','roc_auc']\n",
        "\n",
        "# Calculate the scores with cross-validation\n",
        "scores = cross_validate(grid.best_estimator_, x.values, y_bin, scoring=scoring, cv=20)\n",
        "\n",
        "# Calculate the means of the score\n",
        "mean_accuracy = mean(scores['test_accuracy'])\n",
        "mean_precision = mean(scores['test_precision'])\n",
        "mean_f1 = mean(scores['test_f1'])\n",
        "mean_roc_auc = mean(scores['test_roc_auc'])\n",
        "mean_recall = mean(scores['test_recall'])\n",
        "print(f'mean accuracy is {mean_accuracy}')\n",
        "print(f'mean precision is {mean_precision}')\n",
        "print(f'mean f1 is {mean_f1}')\n",
        "print(f'mean roc_auc is {mean_roc_auc}')\n",
        "print(f'mean recall is {mean_recall}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA8fFgrxvPf2",
        "colab_type": "text"
      },
      "source": [
        "# RF classifier\n",
        "Hyperparameter optimization of RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVwJ1LmWI15D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hyperparameters for RF\n",
        "forest_parameters = {'n_estimators': list(range(50,301)), \n",
        "                   'criterion':  ['gini', 'entropy'],\n",
        "                   'max_depth': [4, 5, 6, 7, 8, 9, 10],\n",
        "                   'max_features': ['auto','sqrt','log2']}\n",
        "\n",
        "# Perform randomized search with cross-validation for hyperparameter optimization\n",
        "grid = RandomizedSearchCV(RandomForestClassifier(), forest_parameters, refit = True, n_iter=10, random_state=42, verbose = 3)  \n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"The best classifier is: \", grid.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guvGtwCDxYYg",
        "colab_type": "text"
      },
      "source": [
        "ROC of RF for train- and test-set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5z9WkIDvdU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determine scores for train and test set\n",
        "score_train = grid.best_estimator_.predict_proba(X_train)\n",
        "score_test = grid.best_estimator_.predict_proba(X_test)\n",
        "\n",
        "# Plot ROC curve for train and test set\n",
        "plot_roc_curve(score_train, y_train_bin)\n",
        "plot_roc_curve(score_test, y_test_bin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIqLhDypyH1R",
        "colab_type": "text"
      },
      "source": [
        "Calculate metrics of RF with cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK6NVlN9UqTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the scoring metrics\n",
        "scoring = ['precision', 'recall', 'f1', 'accuracy','roc_auc']\n",
        "\n",
        "# Calculate the scores with cross-validation\n",
        "scores = cross_validate(grid.best_estimator_, x.values, y_bin, scoring=scoring, cv=20)\n",
        "\n",
        "# Calculate the means of the score\n",
        "mean_accuracy = mean(scores['test_accuracy'])\n",
        "mean_precision = mean(scores['test_precision'])\n",
        "mean_f1 = mean(scores['test_f1'])\n",
        "mean_roc_auc = mean(scores['test_roc_auc'])\n",
        "mean_recall = mean(scores['test_recall'])\n",
        "print(f'mean accuracy is {mean_accuracy}')\n",
        "print(f'mean precision is {mean_precision}')\n",
        "print(f'mean f1 is {mean_f1}')\n",
        "print(f'mean roc_auc is {mean_roc_auc}')\n",
        "print(f'mean recall is {mean_recall}')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}